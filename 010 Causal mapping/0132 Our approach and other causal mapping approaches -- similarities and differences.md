
See also [[0130 A brief history of causal mapping]]

> From [Powell, Copestake, et al. (2023]()


Table 1 shows some highlights from the extensive literature on causal mapping. Many of the key ideas were already in place by the end of the 1970s. The subsequent literature covers a variety of specific techniques to elicit maps from documents, individuals, sets of individuals and groups, with or without software support, following protocols from the purely open-ended to those which use strictly pre-defined lists of factors and links (see Hodgkinson et al (2004) for a comparison of methods), and with aims ranging from strictly idiographic (understanding individuals in specific contexts as Axelrod did) to more nomothetic, such as Tegarden et al. (2016). Renewed interest in causal mapping may also be reinforced by the ‘causal revolution’ in quantitative data science initiated by Judea Pearl (Pearl, 2000; Pearl and Mackenzie, 2018), which has fundamentally challenged the almost total taboo placed on making or assessing explicit causal claims, which was dominant in statistics for much of the twentieth century (Powell, 2018), and this has in turn helped rekindle interest in explicitly addressing causation using qualitative methods.

Causal mapping and most related approaches share the basic idea that causal knowledge – whether generalised or about a specific case or context – can be at least partially captured in small, relatively portable ‘nuggets’ of information (Powell, 2018: 52). These can be assembled into larger models of how things worked, or might work, in some cases. More ambitiously, they may contribute to constructing ‘middle-level theory’ theory, useful for understanding causal processes in other contexts, without necessarily reaching the level of overarching scientific laws (Cartwright, 2020). Causal nuggets are also related to the mechanisms that help to explain how people behave in different contexts (Pawson and Tilley, 1997; Schmitt, 2020). These can be thought of as causal schema and linked to the hypothesis that human knowledge is stored in chunks that are activated and combined with others in relevant circumstances. This would suggest that we humans do not have a comprehensive set of causal maps in our heads at any one time, but we do have a set of more basic components and the ability to assemble them when the situation calls for it, including when prompted by a researcher.

  Table 1. Major milestones in the development of the evaluation tool ‘causal mapping’ – the collection, coding and visualisation of interconnected causal claims.

| Reference                                                                   | Main Application of Causal Mapping                                                                              | Mode of Construction                                                                                                                                                  | Dealing with Multiple Sources                                     | Analysis Procedures                                                                                                                         |
| --------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------- |
| [Axelrod, 1976](https://www.zotero.org/google-docs/?ucqLhD)                 | Understand and critique decision making                                                                         | Coding documents                                                                                                                                                      | Mainly idiographic                                                | Compute polarity of indirect effects in some cases.                                                                                         |
| [Bougon et al., 1977](https://www.zotero.org/google-docs/?1vHDMS)           | Understand how organisations are constructed and can be influenced.                                             | Semi-structured interview to identify a fixed list of factors (“variables”); respondents indicate links and polarity.                                                 | Compare individual maps and combine into global “average” map.    | Identify variables with high outdegree/indegree; construct ‘etiograph’ to show multiple paths; discuss respondent influence over variables. |
| (Ackermann & Eden, 2004, 2011; Eden, 1992; Eden et al., 1979, 1992)         | Decision support and problem solving in organisations. Maps as useful tools rather than research about reality. | Open interviewing based on Kelly’s Personal Construct Theory; direct group map construction (1988).                                                                   | Compare individual maps and analyse group maps directly.          | Structural measures, isolated clusters, hierarchical trees, loops; simplify maps by collapsing X→Y→Z into X→Z.                              |
| (Laukkanen, 1994, 2012; Laukkanen & Eriksson, 2013; Laukkanen & Wang, 2016) | Explicitly cognitive, to improve knowledge and understanding in management                                      | Systematic comparative method with semi-structured interviewing: anchor topics, causes/effects, standardise factor names; comprehensive coverage of map construction. | Comparative study of individual maps, combine data into database. | Display combined maps for subgroups (e.g., all local managers).                                                                             |

  This approach suggests that our everyday causal understanding is as primary as our perception of, say, colour and arises from more than empirical observations of associations between objects or events; our ability to infer causation goes beyond and is not primarily based on noting correlations. And for all its complexity and intuitive brilliance, it is also just as fallible as our perception of colour or size.

  This reaffirms our practice as evaluators of taking the causal claims and opinions of humans (experts and non-experts) seriously (Maxwell, 2004a, 2004b); indeed, this kind of information is the bread and butter of most evaluations.

   
