Can evaluators find a niche in auditing whether AI applications are trustworthy, culture-aware, valid and transparent?

What would need to change in AI systems to make them suitable for a transformational agenda? Can evaluators position themselves as professionals with the right skill set to make this happen, monitoring the transparency, trustworthiness and (cultural) validity of AI applications?  And how will evaluators build the necessary competencies to take this agenda forward?